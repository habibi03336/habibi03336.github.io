---

title: Memory hierarchy
date: 2022-5-4
categories:
    - CS
    - Computer Architecture
    
tags:
    - TIL
---

메모리 계층은 메모리가 접근속도-메모리사이즈-가격에 따라 계층적으로 구성된 것을 말한다. 접근 속도가 빠를 수록 메모리 사이즈는 작아지고 가격을 올라간다. CPU가 가장 빠르게 접근할 수 있는 메모리는 register이다. 다음은 cache인데 CPU 기판에 붙어있는 Level1-cache(on-chip)와 CPU와 물리적으로 분리된 Level2-cache(off-chip)가 있다. 메모리 계층의 가장 하위 부분은 memory와 disk이다.

cache 부분의 속도가 평균적(level1 & level2)으로 10ns 정도 나온다고 한다. 이는 메모리 접근 속도인 112ns보다 10배 빠르다. 그리고 SDD의 접근 속도인 100,000ns보다 10,000배 빠르다.

CPU와 DRAM의 성능 차이가 크기 때문에 이는 컴퓨터 성능 향상의 큰 병목구간이다. 따라서 최대한 많은 데이터를 cache 수준에서 참조할 수 있게 하는 것이 성능 향상에 매우 중요하다. 이것이 가능한 이유는 어떤 데이터가 접근될지 예상할 수 있기 때문인데, 이는 데이터 참조에 지역성(locality)가 있기 때문이다. 지역성이란 한 번 참조된 데이터가 또 접근될 확률이 높다는 Temporal locality와 한 번 접근된 데이터의 주변 데이터가 쓰일 확률이 높다는 Spatial locality를 의미한다.

---

메모리 계층 구조를 이용하여 access time을 줄이고자 할 때, 다음과 같은 중심 질문이 제기된다.
1. 데이터블럭(line)이 캐시에 어떻게 놓여야 하는가?
2. 캐시에 원하는 데이터블럭(line)이 있는지 어떻게 확인할 수 있는가?
3. 예상이 맞지 않을 때, 캐시에 있는 데이터를 어떤 데이터로 대체해야 하는가?
4. 캐시에 write이 일어날 때 하위 메모리와의 데이터 일관성을 어떻게 유지할 수 있는가?

---


